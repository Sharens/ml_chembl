# ML ChEMBL Data Platform

Projekt stanowi platformÄ™ danych oraz Å›rodowisko analityczne do pracy z bazÄ… chemicznÄ… **ChEMBL**. ÅÄ…czy w sobie narzÄ™dzia do inÅ¼ynierii danych (ETL), analizy eksploracyjnej (EDA) oraz uczenia maszynowego w celu predykcji aktywnoÅ›ci biologicznej zwiÄ…zkÃ³w chemicznych.

## ğŸš€ Cel projektu

GÅ‚Ã³wnym celem jest zautomatyzowanie pobierania danych o aktywnoÅ›ciach chemicznych (np. IC50) dla konkretnych celÃ³w biologicznych (Targets), ich przetwarzanie przy uÅ¼yciu wydajnych bibliotek (Polars, Spark) oraz budowa modeli uczenia maszynowego.

## ğŸ›  Technologie i biblioteki

* **JÄ™zyk:** Python 3.12+.
* **Przetwarzanie danych:** `Polars` (szybka alternatywa dla Pandas), `PySpark`.
* **Cheminformatyka:** `RDKit`, `chembl_webresource_client`.
* **ML:** `scikit-learn`, `numpy`.
* **Infrastruktura:** Docker, Docker Compose (Apache Spark, Airflow).
* **Formaty danych:** Parquet (wysoka wydajnoÅ›Ä‡ odczytu).

## ğŸ“‚ Struktura repozytorium

```text
ml_chembl/
â”œâ”€â”€ libs/
â”‚   â”œâ”€â”€ datasets/           # Przetworzone pliki .parquet (np. chembl_selected_ds.parquet)
â”‚   â”œâ”€â”€ queries/            # Zapytania SQL do bazy SQLite ChEMBL
â”‚   â”œâ”€â”€ chembl_downloader.py # Skrypt pobierajÄ…cy dane z lokalnej bazy SQLite
â”‚   â”œâ”€â”€ csv2parquet.py      # NarzÄ™dzie do konwersji plikÃ³w CSV na Parquet
â”‚   â””â”€â”€ misc.py             # Funkcje pomocnicze (Å‚adowanie i czyszczenie danych)
â”œâ”€â”€ spark_airflow/          # Konfiguracja Å›rodowiska rozproszonego
â”‚   â”œâ”€â”€ DockerCompose.yml   # Klaster Spark (Master + Workers)
â”‚   â””â”€â”€ data_platform/      # Konteneryzacja platformy danych
â”œâ”€â”€ eda.ipynb               # Notebook z eksploracyjnÄ… analizÄ… danych i pobieraniem przez API
â”œâ”€â”€ main.ipynb              # GÅ‚Ã³wny proces uczenia maszynowego (preprocessing i modelowanie)
â”œâ”€â”€ requirements.txt        # Lista zaleÅ¼noÅ›ci Python
â””â”€â”€ .gitignore              # Ignorowane pliki (Å›rodowiska wirtualne, duÅ¼e bazy danych)

```

## âš™ï¸ Instalacja i Uruchomienie

### 1. Åšrodowisko lokalne Python

Zaleca siÄ™ uÅ¼ycie Å›rodowiska wirtualnego:

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# lub
.venv\Scripts\activate     # Windows

pip install -r requirements.txt

```

### 2. Infrastruktura Docker (Spark)

Aby uruchomiÄ‡ lokalny klaster Spark do przetwarzania duÅ¼ych zbiorÃ³w danych:

```bash
cd spark_airflow
docker-compose -f DockerCompose.yml up -d

```

Spark Master bÄ™dzie dostÄ™pny pod adresem `http://localhost:8080`.

## ğŸ“ˆ PrzepÅ‚yw pracy (Workflow)

1. **Pobieranie danych:** Skrypt `libs/chembl_downloader.py` Å‚Ä…czy siÄ™ z lokalnÄ… bazÄ… SQLite ChEMBL i eksportuje wybrane dane do formatu ramki danych.
2. **Analiza EDA:** W notebooku `eda.ipynb` sprawdzane sÄ… rozkÅ‚ady standardowych wartoÅ›ci aktywnoÅ›ci oraz generowane sÄ… deskryptory chemiczne za pomocÄ… RDKit.
3. **Modelowanie:** Notebook `main.ipynb` wczytuje dane z formatu `.parquet`, dokonuje skalowania cech i trenuje modele predykcyjne.

## ğŸ“ Notatki

* Projekt korzysta z bazy **ChEMBL 36** w formacie SQLite (wymaga pobrania i umieszczenia w `libs/`).
* Wykorzystanie biblioteki `Polars` pozwala na efektywnÄ… pracÄ™ z milionami rekordÃ³w przy niskim zuÅ¼yciu pamiÄ™ci RAM.
